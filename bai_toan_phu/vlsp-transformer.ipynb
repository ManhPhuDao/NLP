{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14188378,"sourceType":"datasetVersion","datasetId":9046357}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"c3037cd8","cell_type":"markdown","source":"# VLSP 2025 MT — Vi → En Transformer (from scratch) with SentencePiece  \n## Final (2×T4 + Token-based Dynamic Batching)\n\nNotebook này:\n- Chia dữ liệu **9/1 train/valid**\n- SentencePiece **Unigram + byte_fallback**\n- Transformer **from scratch** (Pre-LN + GEGLU + weight tying)\n- Training: **AMP + Warmup+Cosine + EMA**\n- DataLoader: **Token-based dynamic batching** (tối ưu cho **2×T4**)\n- Decode: **Beam search**\n- Metrics: **BLEU / TER / METEOR** + error analysis\n","metadata":{}},{"id":"eeb73ee7","cell_type":"code","source":"import os\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T05:19:51.829966Z","iopub.execute_input":"2025-12-17T05:19:51.830757Z","iopub.status.idle":"2025-12-17T05:19:51.837318Z","shell.execute_reply.started":"2025-12-17T05:19:51.830726Z","shell.execute_reply":"2025-12-17T05:19:51.836691Z"}},"outputs":[],"execution_count":1},{"id":"763aa010","cell_type":"code","source":"!pip -q install sentencepiece sacrebleu nltk tqdm regex","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T05:19:51.838662Z","iopub.execute_input":"2025-12-17T05:19:51.838953Z","iopub.status.idle":"2025-12-17T05:19:56.564770Z","shell.execute_reply.started":"2025-12-17T05:19:51.838918Z","shell.execute_reply":"2025-12-17T05:19:56.564117Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":2},{"id":"e9e622a0","cell_type":"code","source":"import os, re, math, json, random, unicodedata\nfrom dataclasses import dataclass\nfrom typing import List, Tuple\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, Sampler\nfrom torch.nn.utils.rnn import pad_sequence\nfrom tqdm.auto import tqdm\n\nimport sentencepiece as spm\nimport sacrebleu\nfrom sacrebleu.metrics import TER\n\nimport nltk\nnltk.download('wordnet')\nnltk.download('omw-1.4')\nfrom nltk.translate.meteor_score import meteor_score\n\nSEED = 42\nrandom.seed(SEED); np.random.seed(SEED)\ntorch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Device:', device)\nif torch.cuda.is_available():\n    print('GPU0:', torch.cuda.get_device_name(0))\nprint('GPU count:', torch.cuda.device_count())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T05:19:56.566530Z","iopub.execute_input":"2025-12-17T05:19:56.566755Z","iopub.status.idle":"2025-12-17T05:20:02.489492Z","shell.execute_reply.started":"2025-12-17T05:19:56.566723Z","shell.execute_reply":"2025-12-17T05:20:02.488742Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n","output_type":"stream"},{"name":"stdout","text":"Device: cuda\nGPU0: Tesla T4\nGPU count: 2\n","output_type":"stream"}],"execution_count":3},{"id":"9e3ef931","cell_type":"markdown","source":"## 1) Data (9/1 train/valid)","metadata":{}},{"id":"ffab9dca","cell_type":"code","source":"DATA_DIR = \"/kaggle/input/dataset2/MedicalDataset_VLSP\"\nTRAIN_VI = os.path.join(DATA_DIR, \"train.vi.txt\")\nTRAIN_EN = os.path.join(DATA_DIR, \"train.en.txt\")\nPUB_VI   = os.path.join(DATA_DIR, \"public_test.vi.txt\")\nPUB_EN   = os.path.join(DATA_DIR, \"public_test.en.txt\")\n\nfor p in [TRAIN_VI, TRAIN_EN, PUB_VI, PUB_EN]:\n    print(p, \"=>\", \"OK\" if os.path.exists(p) else \"NOT FOUND\")\n\nassert os.path.exists(TRAIN_VI) and os.path.exists(TRAIN_EN)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T05:20:02.490516Z","iopub.execute_input":"2025-12-17T05:20:02.491219Z","iopub.status.idle":"2025-12-17T05:20:02.503821Z","shell.execute_reply.started":"2025-12-17T05:20:02.491191Z","shell.execute_reply":"2025-12-17T05:20:02.503254Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/dataset2/MedicalDataset_VLSP/train.vi.txt => OK\n/kaggle/input/dataset2/MedicalDataset_VLSP/train.en.txt => OK\n/kaggle/input/dataset2/MedicalDataset_VLSP/public_test.vi.txt => OK\n/kaggle/input/dataset2/MedicalDataset_VLSP/public_test.en.txt => OK\n","output_type":"stream"}],"execution_count":4},{"id":"42f30fa7","cell_type":"code","source":"def normalize_vi(x: str) -> str:\n    x = unicodedata.normalize(\"NFC\", x)\n    x = re.sub(r\"\\s+\", \" \", x).strip()\n    x = re.sub(r\"\\s+([,.;:!?])\", r\"\\1\", x)\n    return x\n\ndef normalize_en(x: str) -> str:\n    x = unicodedata.normalize(\"NFC\", x)\n    x = re.sub(r\"\\s+\", \" \", x).strip()\n    x = re.sub(r\"\\s+([,.;:!?])\", r\"\\1\", x)\n    return x\n\ndef load_parallel(path_vi: str, path_en: str) -> Tuple[List[str], List[str]]:\n    with open(path_vi, encoding=\"utf-8\") as f1, open(path_en, encoding=\"utf-8\") as f2:\n        vi = [normalize_vi(l.strip()) for l in f1]\n        en = [normalize_en(l.strip()) for l in f2]\n    n = min(len(vi), len(en))\n    return vi[:n], en[:n]\n\nvi_all, en_all = load_parallel(TRAIN_VI, TRAIN_EN)\nprint(\"Total pairs:\", len(vi_all))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T05:20:02.505485Z","iopub.execute_input":"2025-12-17T05:20:02.505813Z","iopub.status.idle":"2025-12-17T05:20:18.314006Z","shell.execute_reply.started":"2025-12-17T05:20:02.505790Z","shell.execute_reply":"2025-12-17T05:20:18.313350Z"}},"outputs":[{"name":"stdout","text":"Total pairs: 500000\n","output_type":"stream"}],"execution_count":5},{"id":"298b6137","cell_type":"code","source":"idx = np.arange(len(vi_all))\nrng = np.random.default_rng(SEED)\nrng.shuffle(idx)\n\nsplit = int(0.9 * len(idx))\ntrain_idx, valid_idx = idx[:split], idx[split:]\n\ntrain_vi = [vi_all[i] for i in train_idx]\ntrain_en = [en_all[i] for i in train_idx]\nvalid_vi = [vi_all[i] for i in valid_idx]\nvalid_en = [en_all[i] for i in valid_idx]\n\nprint(\"Train:\", len(train_vi), \"Valid:\", len(valid_vi))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T05:20:18.314950Z","iopub.execute_input":"2025-12-17T05:20:18.315236Z","iopub.status.idle":"2025-12-17T05:20:18.570958Z","shell.execute_reply.started":"2025-12-17T05:20:18.315210Z","shell.execute_reply":"2025-12-17T05:20:18.570332Z"}},"outputs":[{"name":"stdout","text":"Train: 450000 Valid: 50000\n","output_type":"stream"}],"execution_count":6},{"id":"b86c08c7","cell_type":"markdown","source":"## 2) SentencePiece (Unigram + byte_fallback)","metadata":{}},{"id":"9698188c","cell_type":"code","source":"SP_DIR = \"./spm\"\nos.makedirs(SP_DIR, exist_ok=True)\n\nSRC_MODEL_PREFIX = os.path.join(SP_DIR, \"spm_vi\")\nTRG_MODEL_PREFIX = os.path.join(SP_DIR, \"spm_en\")\n\nSRC_VOCAB_SIZE = 24000\nTRG_VOCAB_SIZE = 24000\n\nvi_txt = os.path.join(SP_DIR, \"train_vi.txt\")\nen_txt = os.path.join(SP_DIR, \"train_en.txt\")\n\nif not os.path.exists(vi_txt):\n    with open(vi_txt, \"w\", encoding=\"utf-8\") as f:\n        f.write(\"\\n\".join(train_vi))\nif not os.path.exists(en_txt):\n    with open(en_txt, \"w\", encoding=\"utf-8\") as f:\n        f.write(\"\\n\".join(train_en))\n\nif not os.path.exists(SRC_MODEL_PREFIX + \".model\"):\n    spm.SentencePieceTrainer.Train(\n        input=vi_txt,\n        model_prefix=SRC_MODEL_PREFIX,\n        vocab_size=SRC_VOCAB_SIZE,\n        model_type=\"unigram\",\n        character_coverage=0.9995,\n        byte_fallback=True,\n        pad_id=0, unk_id=1, bos_id=2, eos_id=3\n    )\n\nif not os.path.exists(TRG_MODEL_PREFIX + \".model\"):\n    spm.SentencePieceTrainer.Train(\n        input=en_txt,\n        model_prefix=TRG_MODEL_PREFIX,\n        vocab_size=TRG_VOCAB_SIZE,\n        model_type=\"unigram\",\n        character_coverage=1.0,\n        byte_fallback=True,\n        pad_id=0, unk_id=1, bos_id=2, eos_id=3\n    )\n\nsp_src = spm.SentencePieceProcessor(model_file=SRC_MODEL_PREFIX + \".model\")\nsp_trg = spm.SentencePieceProcessor(model_file=TRG_MODEL_PREFIX + \".model\")\n\nPAD, UNK, BOS, EOS = 0, 1, 2, 3\n\nprint(\"SRC vocab:\", sp_src.get_piece_size(), \"TRG vocab:\", sp_trg.get_piece_size())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T05:20:18.571855Z","iopub.execute_input":"2025-12-17T05:20:18.572111Z","iopub.status.idle":"2025-12-17T05:22:07.845607Z","shell.execute_reply.started":"2025-12-17T05:20:18.572088Z","shell.execute_reply":"2025-12-17T05:22:07.843326Z"}},"outputs":[{"name":"stdout","text":"SRC vocab: 24000 TRG vocab: 24000\n","output_type":"stream"},{"name":"stderr","text":"sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \ntrainer_spec {\n  input: ./spm/train_vi.txt\n  input_format: \n  model_prefix: ./spm/spm_vi\n  model_type: UNIGRAM\n  vocab_size: 24000\n  self_test_sample_size: 0\n  character_coverage: 0.9995\n  input_sentence_size: 0\n  shuffle_input_sentence: 1\n  seed_sentencepiece_size: 1000000\n  shrinking_factor: 0.75\n  max_sentence_length: 4192\n  num_threads: 16\n  num_sub_iterations: 2\n  max_sentencepiece_length: 16\n  split_by_unicode_script: 1\n  split_by_number: 1\n  split_by_whitespace: 1\n  split_digits: 0\n  pretokenization_delimiter: \n  treat_whitespace_as_suffix: 0\n  allow_whitespace_only_pieces: 0\n  required_chars: \n  byte_fallback: 1\n  vocabulary_output_piece_score: 1\n  train_extremely_large_corpus: 0\n  seed_sentencepieces_file: \n  hard_vocab_limit: 1\n  use_all_vocab: 0\n  unk_id: 1\n  bos_id: 2\n  eos_id: 3\n  pad_id: 0\n  unk_piece: <unk>\n  bos_piece: <s>\n  eos_piece: </s>\n  pad_piece: <pad>\n  unk_surface:  ⁇ \n  enable_differential_privacy: 0\n  differential_privacy_noise_level: 0\n  differential_privacy_clipping_threshold: 0\n}\nnormalizer_spec {\n  name: nmt_nfkc\n  add_dummy_prefix: 1\n  remove_extra_whitespaces: 1\n  escape_whitespaces: 1\n  normalization_rule_tsv: \n}\ndenormalizer_spec {}\ntrainer_interface.cc(355) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\ntrainer_interface.cc(186) LOG(INFO) Loading corpus: ./spm/train_vi.txt\ntrainer_interface.cc(411) LOG(INFO) Loaded all 450000 sentences\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <pad>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <unk>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <s>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: </s>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x00>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x01>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x02>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x03>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x04>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x05>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x06>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x07>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x08>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x09>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x0A>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x0B>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x0C>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x0D>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x0E>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x0F>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x10>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x11>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x12>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x13>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x14>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x15>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x16>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x17>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x18>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x19>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x1A>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x1B>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x1C>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x1D>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x1E>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x1F>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x20>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x21>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x22>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x23>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x24>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x25>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x26>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x27>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x28>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x29>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x2A>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x2B>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x2C>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x2D>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x2E>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x2F>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x30>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x31>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x32>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x33>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x34>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x35>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x36>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x37>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x38>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x39>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x3A>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x3B>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x3C>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x3D>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x3E>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x3F>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x40>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x41>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x42>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x43>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x44>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x45>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x46>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x47>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x48>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x49>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x4A>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x4B>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x4C>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x4D>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x4E>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x4F>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x50>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x51>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x52>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x53>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x54>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x55>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x56>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x57>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x58>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x59>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x5A>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x5B>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x5C>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x5D>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x5E>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x5F>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x60>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x61>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x62>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x63>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x64>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x65>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x66>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x67>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x68>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x69>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x6A>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x6B>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x6C>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x6D>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x6E>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x6F>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x70>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x71>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x72>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x73>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x74>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x75>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x76>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x77>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x78>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x79>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x7A>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x7B>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x7C>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x7D>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x7E>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x7F>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x80>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x81>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x82>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x83>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x84>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x85>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x86>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x87>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x88>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x89>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x8A>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x8B>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x8C>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x8D>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x8E>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x8F>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x90>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x91>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x92>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x93>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x94>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x95>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x96>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x97>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x98>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x99>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x9A>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x9B>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x9C>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x9D>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x9E>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x9F>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xA0>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xA1>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xA2>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xA3>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xA4>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xA5>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xA6>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xA7>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xA8>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xA9>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xAA>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xAB>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xAC>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xAD>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xAE>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xAF>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xB0>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xB1>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xB2>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xB3>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xB4>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xB5>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xB6>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xB7>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xB8>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xB9>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xBA>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xBB>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xBC>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xBD>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xBE>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xBF>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xC0>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xC1>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xC2>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xC3>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xC4>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xC5>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xC6>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xC7>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xC8>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xC9>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xCA>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xCB>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xCC>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xCD>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xCE>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xCF>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xD0>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xD1>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xD2>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xD3>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xD4>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xD5>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xD6>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xD7>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xD8>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xD9>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xDA>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xDB>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xDC>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xDD>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xDE>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xDF>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xE0>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xE1>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xE2>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xE3>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xE4>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xE5>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xE6>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xE7>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xE8>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xE9>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xEA>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xEB>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xEC>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xED>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xEE>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xEF>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xF0>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xF1>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xF2>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xF3>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xF4>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xF5>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xF6>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xF7>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xF8>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xF9>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xFA>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xFB>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xFC>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xFD>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xFE>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xFF>\ntrainer_interface.cc(432) LOG(INFO) Normalizing sentences...\ntrainer_interface.cc(541) LOG(INFO) all chars count=62650716\ntrainer_interface.cc(552) LOG(INFO) Done: 99.9507% characters are covered.\ntrainer_interface.cc(562) LOG(INFO) Alphabet size=159\ntrainer_interface.cc(563) LOG(INFO) Final character coverage=0.999507\ntrainer_interface.cc(594) LOG(INFO) Done! preprocessed 450000 sentences.\nunigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\nunigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=39120019\nunigram_model_trainer.cc(312) LOG(INFO) Initialized 184283 seed sentencepieces\ntrainer_interface.cc(600) LOG(INFO) Tokenizing input sentences with whitespace: 450000\ntrainer_interface.cc(611) LOG(INFO) Done! 183178\nunigram_model_trainer.cc(602) LOG(INFO) Using 183178 sentences for EM training\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=92034 obj=9.79974 num_tokens=390110 num_tokens/piece=4.23876\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=79411 obj=8.09816 num_tokens=388868 num_tokens/piece=4.8969\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=59544 obj=8.02967 num_tokens=404807 num_tokens/piece=6.79845\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=59514 obj=8.02227 num_tokens=405258 num_tokens/piece=6.80946\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=44631 obj=8.0416 num_tokens=429008 num_tokens/piece=9.61233\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=44627 obj=8.03701 num_tokens=428984 num_tokens/piece=9.61266\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=33470 obj=8.06437 num_tokens=454846 num_tokens/piece=13.5897\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=33470 obj=8.05827 num_tokens=454731 num_tokens/piece=13.5862\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=26400 obj=8.08882 num_tokens=478396 num_tokens/piece=18.1211\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=26400 obj=8.08322 num_tokens=478329 num_tokens/piece=18.1185\ntrainer_interface.cc(689) LOG(INFO) Saving model: ./spm/spm_vi.model\ntrainer_interface.cc(701) LOG(INFO) Saving vocabs: ./spm/spm_vi.vocab\nsentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \ntrainer_spec {\n  input: ./spm/train_en.txt\n  input_format: \n  model_prefix: ./spm/spm_en\n  model_type: UNIGRAM\n  vocab_size: 24000\n  self_test_sample_size: 0\n  character_coverage: 1\n  input_sentence_size: 0\n  shuffle_input_sentence: 1\n  seed_sentencepiece_size: 1000000\n  shrinking_factor: 0.75\n  max_sentence_length: 4192\n  num_threads: 16\n  num_sub_iterations: 2\n  max_sentencepiece_length: 16\n  split_by_unicode_script: 1\n  split_by_number: 1\n  split_by_whitespace: 1\n  split_digits: 0\n  pretokenization_delimiter: \n  treat_whitespace_as_suffix: 0\n  allow_whitespace_only_pieces: 0\n  required_chars: \n  byte_fallback: 1\n  vocabulary_output_piece_score: 1\n  train_extremely_large_corpus: 0\n  seed_sentencepieces_file: \n  hard_vocab_limit: 1\n  use_all_vocab: 0\n  unk_id: 1\n  bos_id: 2\n  eos_id: 3\n  pad_id: 0\n  unk_piece: <unk>\n  bos_piece: <s>\n  eos_piece: </s>\n  pad_piece: <pad>\n  unk_surface:  ⁇ \n  enable_differential_privacy: 0\n  differential_privacy_noise_level: 0\n  differential_privacy_clipping_threshold: 0\n}\nnormalizer_spec {\n  name: nmt_nfkc\n  add_dummy_prefix: 1\n  remove_extra_whitespaces: 1\n  escape_whitespaces: 1\n  normalization_rule_tsv: \n}\ndenormalizer_spec {}\ntrainer_interface.cc(355) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\ntrainer_interface.cc(186) LOG(INFO) Loading corpus: ./spm/train_en.txt\ntrainer_interface.cc(411) LOG(INFO) Loaded all 450000 sentences\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <pad>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <unk>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <s>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: </s>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x00>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x01>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x02>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x03>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x04>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x05>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x06>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x07>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x08>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x09>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x0A>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x0B>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x0C>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x0D>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x0E>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x0F>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x10>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x11>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x12>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x13>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x14>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x15>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x16>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x17>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x18>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x19>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x1A>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x1B>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x1C>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x1D>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x1E>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x1F>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x20>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x21>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x22>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x23>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x24>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x25>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x26>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x27>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x28>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x29>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x2A>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x2B>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x2C>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x2D>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x2E>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x2F>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x30>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x31>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x32>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x33>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x34>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x35>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x36>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x37>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x38>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x39>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x3A>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x3B>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x3C>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x3D>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x3E>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x3F>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x40>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x41>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x42>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x43>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x44>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x45>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x46>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x47>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x48>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x49>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x4A>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x4B>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x4C>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x4D>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x4E>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x4F>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x50>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x51>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x52>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x53>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x54>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x55>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x56>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x57>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x58>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x59>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x5A>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x5B>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x5C>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x5D>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x5E>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x5F>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x60>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x61>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x62>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x63>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x64>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x65>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x66>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x67>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x68>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x69>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x6A>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x6B>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x6C>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x6D>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x6E>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x6F>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x70>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x71>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x72>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x73>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x74>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x75>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x76>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x77>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x78>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x79>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x7A>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x7B>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x7C>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x7D>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x7E>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x7F>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x80>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x81>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x82>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x83>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x84>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x85>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x86>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x87>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x88>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x89>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x8A>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x8B>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x8C>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x8D>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x8E>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x8F>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x90>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x91>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x92>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x93>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x94>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x95>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x96>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x97>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x98>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x99>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x9A>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x9B>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x9C>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x9D>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x9E>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0x9F>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xA0>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xA1>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xA2>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xA3>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xA4>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xA5>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xA6>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xA7>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xA8>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xA9>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xAA>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xAB>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xAC>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xAD>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xAE>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xAF>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xB0>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xB1>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xB2>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xB3>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xB4>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xB5>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xB6>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xB7>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xB8>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xB9>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xBA>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xBB>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xBC>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xBD>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xBE>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xBF>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xC0>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xC1>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xC2>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xC3>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xC4>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xC5>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xC6>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xC7>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xC8>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xC9>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xCA>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xCB>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xCC>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xCD>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xCE>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xCF>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xD0>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xD1>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xD2>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xD3>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xD4>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xD5>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xD6>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xD7>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xD8>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xD9>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xDA>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xDB>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xDC>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xDD>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xDE>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xDF>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xE0>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xE1>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xE2>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xE3>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xE4>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xE5>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xE6>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xE7>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xE8>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xE9>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xEA>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xEB>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xEC>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xED>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xEE>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xEF>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xF0>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xF1>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xF2>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xF3>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xF4>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xF5>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xF6>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xF7>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xF8>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xF9>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xFA>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xFB>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xFC>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xFD>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xFE>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <0xFF>\ntrainer_interface.cc(432) LOG(INFO) Normalizing sentences...\ntrainer_interface.cc(541) LOG(INFO) all chars count=64122495\ntrainer_interface.cc(552) LOG(INFO) Done: 100% characters are covered.\ntrainer_interface.cc(562) LOG(INFO) Alphabet size=305\ntrainer_interface.cc(563) LOG(INFO) Final character coverage=1\ntrainer_interface.cc(594) LOG(INFO) Done! preprocessed 450000 sentences.\nunigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\nunigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=41044566\nunigram_model_trainer.cc(312) LOG(INFO) Initialized 341439 seed sentencepieces\ntrainer_interface.cc(600) LOG(INFO) Tokenizing input sentences with whitespace: 450000\ntrainer_interface.cc(611) LOG(INFO) Done! 288654\nunigram_model_trainer.cc(602) LOG(INFO) Using 288654 sentences for EM training\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=139164 obj=11.9384 num_tokens=622344 num_tokens/piece=4.47202\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=118469 obj=9.19393 num_tokens=622686 num_tokens/piece=5.25611\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=88841 obj=9.17507 num_tokens=647881 num_tokens/piece=7.29259\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=88801 obj=9.16474 num_tokens=648686 num_tokens/piece=7.30494\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=66597 obj=9.2149 num_tokens=689710 num_tokens/piece=10.3565\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=66590 obj=9.20305 num_tokens=689803 num_tokens/piece=10.359\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=49941 obj=9.28308 num_tokens=736370 num_tokens/piece=14.7448\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=49941 obj=9.26759 num_tokens=736281 num_tokens/piece=14.743\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=37455 obj=9.38266 num_tokens=789639 num_tokens/piece=21.0823\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=37455 obj=9.36206 num_tokens=789625 num_tokens/piece=21.082\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=28090 obj=9.51547 num_tokens=846895 num_tokens/piece=30.1493\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=28090 obj=9.48907 num_tokens=846848 num_tokens/piece=30.1477\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=26400 obj=9.52307 num_tokens=858518 num_tokens/piece=32.5196\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=26400 obj=9.5176 num_tokens=858566 num_tokens/piece=32.5214\ntrainer_interface.cc(689) LOG(INFO) Saving model: ./spm/spm_en.model\ntrainer_interface.cc(701) LOG(INFO) Saving vocabs: ./spm/spm_en.vocab\n","output_type":"stream"}],"execution_count":7},{"id":"09bfb74f","cell_type":"markdown","source":"## 3) Dataset + Token-based Dynamic Batching (2×T4 preset)\n\nThiết lập token budget lớn hơn để tận dụng 2 GPU.  \nNếu gặp OOM, giảm `MAX_TOKENS_TRAIN` theo bậc 4000.\n","metadata":{}},{"id":"2cd1b35b","cell_type":"code","source":"MAX_LEN = 80\n\nclass SPMT(Dataset):\n    def __init__(self, src_texts, trg_texts, max_len):\n        self.src = src_texts\n        self.trg = trg_texts\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.src)\n\n    def __getitem__(self, i):\n        s_ids = sp_src.encode(self.src[i], out_type=int)[: self.max_len - 2]\n        t_ids = sp_trg.encode(self.trg[i], out_type=int)[: self.max_len - 2]\n        s = [BOS] + s_ids + [EOS]\n        t = [BOS] + t_ids + [EOS]\n        return torch.tensor(s, dtype=torch.long), torch.tensor(t, dtype=torch.long)\n\ndef collate_fn(batch):\n    src, trg = zip(*batch)\n    src = pad_sequence(src, batch_first=True, padding_value=PAD)\n    trg = pad_sequence(trg, batch_first=True, padding_value=PAD)\n    return src, trg\n\ntrain_ds = SPMT(train_vi, train_en, MAX_LEN)\nvalid_ds = SPMT(valid_vi, valid_en, MAX_LEN)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T05:22:07.846795Z","iopub.execute_input":"2025-12-17T05:22:07.847095Z","iopub.status.idle":"2025-12-17T05:22:07.853422Z","shell.execute_reply.started":"2025-12-17T05:22:07.847055Z","shell.execute_reply":"2025-12-17T05:22:07.852842Z"}},"outputs":[],"execution_count":8},{"id":"88b4eb0c","cell_type":"code","source":"def build_lengths_cache(prefix: str, src_texts: List[str], trg_texts: List[str]):\n    path = os.path.join(SP_DIR, f\"{prefix}_toklen.npy\")\n    if os.path.exists(path):\n        return np.load(path)\n    lens = np.zeros(len(src_texts), dtype=np.int32)\n    for i in tqdm(range(len(src_texts)), desc=f\"TokLen {prefix}\"):\n        s = sp_src.encode(src_texts[i], out_type=int)\n        t = sp_trg.encode(trg_texts[i], out_type=int)\n        lens[i] = min(len(s), MAX_LEN-2) + min(len(t), MAX_LEN-2) + 4\n    np.save(path, lens)\n    return lens\n\ntrain_lens = build_lengths_cache(\"train\", train_vi, train_en)\nvalid_lens = build_lengths_cache(\"valid\", valid_vi, valid_en)\n\nprint(\"Train avg tok/sample:\", float(train_lens.mean()))\nprint(\"Valid avg tok/sample:\", float(valid_lens.mean()))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T05:22:07.854337Z","iopub.execute_input":"2025-12-17T05:22:07.854589Z","iopub.status.idle":"2025-12-17T05:22:35.764601Z","shell.execute_reply.started":"2025-12-17T05:22:07.854567Z","shell.execute_reply":"2025-12-17T05:22:35.763829Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"TokLen train:   0%|          | 0/450000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"915c0e5153a54a69bd2d5af5fb084cc7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TokLen valid:   0%|          | 0/50000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df9463d131144293a3fa3f1e388ff213"}},"metadata":{}},{"name":"stdout","text":"Train avg tok/sample: 64.23703333333333\nValid avg tok/sample: 64.20196\n","output_type":"stream"}],"execution_count":9},{"id":"0f1ada8f","cell_type":"code","source":"class TokenBatchSampler(Sampler):\n    def __init__(self, lengths, max_tokens, shuffle=True, drop_last=False, bucket_size=4096, seed=42):\n        self.lengths = np.asarray(lengths, dtype=np.int64)\n        self.max_tokens = int(max_tokens)\n        self.shuffle = bool(shuffle)\n        self.drop_last = bool(drop_last)\n        self.bucket_size = int(bucket_size)\n        self.rng = np.random.default_rng(seed)\n\n    def __iter__(self):\n        idx = np.arange(len(self.lengths))\n        if self.shuffle:\n            self.rng.shuffle(idx)\n\n        if self.bucket_size and self.bucket_size > 0:\n            buckets = [idx[i:i+self.bucket_size] for i in range(0, len(idx), self.bucket_size)]\n            out = []\n            for b in buckets:\n                b = b[np.argsort(self.lengths[b])]\n                out.append(b)\n            idx = np.concatenate(out, axis=0)\n\n        batch = []\n        tok = 0\n        for i in idx:\n            L = int(self.lengths[i])\n            if L > self.max_tokens:\n                if not self.drop_last:\n                    yield [int(i)]\n                continue\n            if tok + L > self.max_tokens and len(batch) > 0:\n                yield batch\n                batch = [int(i)]\n                tok = L\n            else:\n                batch.append(int(i))\n                tok += L\n        if len(batch) > 0 and (not self.drop_last):\n            yield batch\n\n    def __len__(self):\n        cnt = 0\n        tok = 0\n        cur = 0\n        for L in self.lengths:\n            L = int(L)\n            if L > self.max_tokens:\n                if not self.drop_last:\n                    cnt += 1\n                continue\n            if tok + L > self.max_tokens and cur > 0:\n                cnt += 1\n                tok = L\n                cur = 1\n            else:\n                tok += L\n                cur += 1\n        if cur > 0 and (not self.drop_last):\n            cnt += 1\n        return cnt\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T05:22:35.765656Z","iopub.execute_input":"2025-12-17T05:22:35.765903Z","iopub.status.idle":"2025-12-17T05:22:35.832701Z","shell.execute_reply.started":"2025-12-17T05:22:35.765880Z","shell.execute_reply":"2025-12-17T05:22:35.831960Z"}},"outputs":[],"execution_count":10},{"id":"9f1e8702","cell_type":"code","source":"NUM_WORKERS = 2\n\nMAX_TOKENS_TRAIN = 6000\nMAX_TOKENS_VALID = 8000\n\ntrain_batch_sampler = TokenBatchSampler(train_lens, MAX_TOKENS_TRAIN, shuffle=True, drop_last=True, bucket_size=4096, seed=SEED)\nvalid_batch_sampler = TokenBatchSampler(valid_lens, MAX_TOKENS_VALID, shuffle=False, drop_last=False, bucket_size=0, seed=SEED)\n\ntrain_loader = DataLoader(train_ds, batch_sampler=train_batch_sampler, num_workers=NUM_WORKERS, pin_memory=True, collate_fn=collate_fn)\nvalid_loader = DataLoader(valid_ds, batch_sampler=valid_batch_sampler, num_workers=NUM_WORKERS, pin_memory=True, collate_fn=collate_fn)\n\nprint(\"Train batches:\", len(train_loader), \"Valid batches:\", len(valid_loader))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T05:22:35.834865Z","iopub.execute_input":"2025-12-17T05:22:35.835136Z","iopub.status.idle":"2025-12-17T05:22:35.939632Z","shell.execute_reply.started":"2025-12-17T05:22:35.835103Z","shell.execute_reply":"2025-12-17T05:22:35.939117Z"}},"outputs":[{"name":"stdout","text":"Train batches: 4849 Valid batches: 404\n","output_type":"stream"}],"execution_count":11},{"id":"1c773670","cell_type":"markdown","source":"## 4) Transformer from scratch (Pre-LN + GEGLU + weight tying)","metadata":{}},{"id":"cd85d438","cell_type":"code","source":"class PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_len=5000, dropout=0.1):\n        super().__init__()\n        self.drop = nn.Dropout(dropout)\n        pe = torch.zeros(max_len, d_model)\n        pos = torch.arange(0, max_len).unsqueeze(1)\n        div = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(pos * div)\n        pe[:, 1::2] = torch.cos(pos * div)\n        self.register_buffer(\"pe\", pe.unsqueeze(0))\n\n    def forward(self, x):\n        return self.drop(x + self.pe[:, :x.size(1)].to(x.device))\n\nclass TokenEmbedding(nn.Module):\n    def __init__(self, vocab_size, d_model, max_len=5000, dropout=0.1):\n        super().__init__()\n        self.emb = nn.Embedding(vocab_size, d_model)\n        self.pe = PositionalEncoding(d_model, max_len=max_len, dropout=dropout)\n        self.scale = math.sqrt(d_model)\n\n    def forward(self, x):\n        return self.pe(self.emb(x) * self.scale)\n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, d_model, n_heads, dropout=0.1):\n        super().__init__()\n        assert d_model % n_heads == 0\n        self.h = n_heads\n        self.d = d_model // n_heads\n        self.wq = nn.Linear(d_model, d_model)\n        self.wk = nn.Linear(d_model, d_model)\n        self.wv = nn.Linear(d_model, d_model)\n        self.wo = nn.Linear(d_model, d_model)\n        self.drop = nn.Dropout(dropout)\n\n    def forward(self, q, k, v, mask=None):\n        B, Tq, D = q.size()\n\n        def split(x):\n            return x.view(B, -1, self.h, self.d).transpose(1, 2)\n\n        Q = split(self.wq(q))\n        K = split(self.wk(k))\n        V = split(self.wv(v))\n\n        scores = (Q @ K.transpose(-2, -1)) / math.sqrt(self.d)\n        if mask is not None:\n            scores = scores.masked_fill(~mask, torch.finfo(scores.dtype).min)\n\n        attn = torch.softmax(scores, dim=-1)\n        attn = self.drop(attn)\n        out = attn @ V\n        out = out.transpose(1, 2).contiguous().view(B, Tq, D)\n        return self.wo(out)\n\nclass GEGLU(nn.Module):\n    def __init__(self, d_model, d_ff, dropout=0.1):\n        super().__init__()\n        self.fc1 = nn.Linear(d_model, 2*d_ff)\n        self.fc2 = nn.Linear(d_ff, d_model)\n        self.drop = nn.Dropout(dropout)\n\n    def forward(self, x):\n        u, v = self.fc1(x).chunk(2, dim=-1)\n        x = F.gelu(u) * v\n        x = self.drop(x)\n        return self.fc2(x)\n\nclass EncoderLayer(nn.Module):\n    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n        super().__init__()\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.attn = MultiHeadAttention(d_model, n_heads, dropout)\n        self.ffn = GEGLU(d_model, d_ff, dropout)\n        self.drop = nn.Dropout(dropout)\n\n    def forward(self, x, src_mask):\n        h = self.norm1(x)\n        x = x + self.drop(self.attn(h, h, h, src_mask))\n        h = self.norm2(x)\n        x = x + self.drop(self.ffn(h))\n        return x\n\nclass DecoderLayer(nn.Module):\n    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n        super().__init__()\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.norm3 = nn.LayerNorm(d_model)\n        self.self_attn = MultiHeadAttention(d_model, n_heads, dropout)\n        self.cross_attn = MultiHeadAttention(d_model, n_heads, dropout)\n        self.ffn = GEGLU(d_model, d_ff, dropout)\n        self.drop = nn.Dropout(dropout)\n\n    def forward(self, x, enc, trg_mask, src_mask):\n        h = self.norm1(x)\n        x = x + self.drop(self.self_attn(h, h, h, trg_mask))\n        h = self.norm2(x)\n        x = x + self.drop(self.cross_attn(h, enc, enc, src_mask))\n        h = self.norm3(x)\n        x = x + self.drop(self.ffn(h))\n        return x\n\ndef make_src_mask(src):\n    return (src != PAD).unsqueeze(1).unsqueeze(2)\n\ndef make_trg_mask(trg):\n    pad_mask = (trg != PAD).unsqueeze(1).unsqueeze(2)\n    T = trg.size(1)\n    causal = torch.tril(torch.ones(T, T, device=trg.device, dtype=torch.bool)).unsqueeze(0).unsqueeze(1)\n    return pad_mask & causal\n\nclass Transformer(nn.Module):\n    def __init__(self, src_vocab, trg_vocab, d_model, n_heads, d_ff, n_enc, n_dec, dropout, max_len):\n        super().__init__()\n        self.src_emb = TokenEmbedding(src_vocab, d_model, max_len=max_len, dropout=dropout)\n        self.trg_emb = TokenEmbedding(trg_vocab, d_model, max_len=max_len, dropout=dropout)\n        self.enc = nn.ModuleList([EncoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_enc)])\n        self.dec = nn.ModuleList([DecoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_dec)])\n        self.norm_e = nn.LayerNorm(d_model)\n        self.norm_d = nn.LayerNorm(d_model)\n        self.fc_out = nn.Linear(d_model, trg_vocab, bias=False)\n        self.fc_out.weight = self.trg_emb.emb.weight\n        for p in self.parameters():\n            if p.dim() > 1:\n                nn.init.xavier_uniform_(p)\n\n    def encode(self, src):\n        src_mask = make_src_mask(src)\n        x = self.src_emb(src)\n        for layer in self.enc:\n            x = layer(x, src_mask)\n        return self.norm_e(x), src_mask\n\n    def decode(self, trg, enc, src_mask):\n        trg_mask = make_trg_mask(trg)\n        x = self.trg_emb(trg)\n        for layer in self.dec:\n            x = layer(x, enc, trg_mask, src_mask)\n        x = self.norm_d(x)\n        return self.fc_out(x)\n\n    def forward(self, src, trg_in):\n        enc, src_mask = self.encode(src)\n        return self.decode(trg_in, enc, src_mask)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T05:22:35.940307Z","iopub.execute_input":"2025-12-17T05:22:35.940510Z","iopub.status.idle":"2025-12-17T05:22:35.961742Z","shell.execute_reply.started":"2025-12-17T05:22:35.940489Z","shell.execute_reply":"2025-12-17T05:22:35.961055Z"}},"outputs":[],"execution_count":12},{"id":"1fdda26c","cell_type":"markdown","source":"## 5) Training (AMP + Warmup+Cosine + EMA)","metadata":{}},{"id":"f9ef9207","cell_type":"code","source":"class LabelSmoothingLoss(nn.Module):\n    def __init__(self, smoothing: float, vocab_size: int, ignore_index: int = PAD):\n        super().__init__()\n        self.smoothing = float(smoothing)\n        self.vocab_size = int(vocab_size)\n        self.ignore_index = int(ignore_index)\n\n    def forward(self, logits, target):\n        logp = F.log_softmax(logits, dim=-1)\n        nll = F.nll_loss(logp, target, reduction='none', ignore_index=self.ignore_index)\n        smooth = -logp.mean(dim=-1)\n        mask = (target != self.ignore_index).float()\n        nll = (nll * mask).sum() / mask.sum().clamp_min(1.0)\n        smooth = (smooth * mask).sum() / mask.sum().clamp_min(1.0)\n        return (1.0 - self.smoothing) * nll + self.smoothing * smooth\n\n@dataclass\nclass HParams:\n    d_model: int = 512\n    n_heads: int = 8\n    d_ff: int = 2048\n    n_enc: int = 6\n    n_dec: int = 6\n    dropout: float = 0.12\n\n    lr: float = 5e-4\n    weight_decay: float = 0.01\n    warmup_steps: int = 4000\n    min_lr_ratio: float = 0.1\n\n    epochs: int = 15\n    grad_clip: float = 1.0\n    accum_steps: int = 4\n    label_smooth: float = 0.1\n\n    use_ema: bool = False\n    ema_decay: float = 0.999\n\nhp = HParams()\n\nSRC_V = sp_src.get_piece_size()\nTRG_V = sp_trg.get_piece_size()\n\nbase_model = Transformer(SRC_V, TRG_V, hp.d_model, hp.n_heads, hp.d_ff, hp.n_enc, hp.n_dec, hp.dropout, max_len=4096).to(device)\nif torch.cuda.device_count() > 1:\n    model = nn.DataParallel(base_model).to(device)\nelse:\n    model = base_model\n\ndef unwrap(m):\n    return m.module if isinstance(m, nn.DataParallel) else m\n\ncriterion = LabelSmoothingLoss(hp.label_smooth, TRG_V, ignore_index=PAD)\noptimizer = torch.optim.AdamW(model.parameters(), lr=hp.lr, betas=(0.9, 0.98), eps=1e-9, weight_decay=hp.weight_decay)\n\nsteps_per_epoch = max(1, len(train_loader) // hp.accum_steps)\ntotal_steps = max(1, hp.epochs * steps_per_epoch)\n\ndef lr_lambda(step):\n    step = max(1, step)\n    if step <= hp.warmup_steps:\n        return step / float(hp.warmup_steps)\n    progress = (step - hp.warmup_steps) / float(max(1, total_steps - hp.warmup_steps))\n    cosine = 0.5 * (1.0 + math.cos(math.pi * progress))\n    return hp.min_lr_ratio + (1.0 - hp.min_lr_ratio) * cosine\n\nscheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\nscaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n\nclass EMA:\n    def __init__(self, model, decay):\n        self.decay = float(decay)\n        self.shadow = {n: p.detach().clone() for n, p in model.named_parameters() if p.requires_grad}\n        self.backup = {}\n\n    @torch.no_grad()\n    def update(self, model):\n        for n, p in model.named_parameters():\n            if p.requires_grad:\n                self.shadow[n].mul_(self.decay).add_(p.detach(), alpha=1.0 - self.decay)\n\n    @torch.no_grad()\n    def apply(self, model):\n        self.backup = {}\n        for n, p in model.named_parameters():\n            if p.requires_grad:\n                self.backup[n] = p.detach().clone()\n                p.data.copy_(self.shadow[n])\n\n    @torch.no_grad()\n    def restore(self, model):\n        for n, p in model.named_parameters():\n            if p.requires_grad:\n                p.data.copy_(self.backup[n])\n        self.backup = {}\n\nema = EMA(unwrap(model), hp.ema_decay) if hp.use_ema else None\n\nprint(\"Params (M):\", sum(p.numel() for p in model.parameters())/1e6)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T05:22:35.962529Z","iopub.execute_input":"2025-12-17T05:22:35.962846Z","iopub.status.idle":"2025-12-17T05:22:40.498315Z","shell.execute_reply.started":"2025-12-17T05:22:35.962823Z","shell.execute_reply":"2025-12-17T05:22:40.497635Z"}},"outputs":[{"name":"stdout","text":"Params (M): 81.324032\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_55/3046772677.py:68: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n","output_type":"stream"}],"execution_count":13},{"id":"f6bbe6e9","cell_type":"code","source":"def run_epoch(model, loader, train: bool):\n    total_loss, total_tok = 0.0, 0\n    if train:\n        model.train()\n    else:\n        model.eval()\n\n    optimizer.zero_grad(set_to_none=True)\n\n    ctx = torch.enable_grad() if train else torch.no_grad()\n    with ctx:\n        for step, (src, trg) in enumerate(tqdm(loader, leave=False), start=1):\n            src = src.to(device, non_blocking=True)\n            trg = trg.to(device, non_blocking=True)\n            trg_in = trg[:, :-1]\n            trg_out = trg[:, 1:]\n\n            with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):\n                logits = model(src, trg_in)\n                loss = criterion(logits.reshape(-1, logits.size(-1)).float(), trg_out.reshape(-1))\n                if train:\n                    loss = loss / hp.accum_steps\n\n            if train:\n                scaler.scale(loss).backward()\n                if step % hp.accum_steps == 0:\n                    scaler.unscale_(optimizer)\n                    torch.nn.utils.clip_grad_norm_(model.parameters(), hp.grad_clip)\n                    scaler.step(optimizer)\n                    scaler.update()\n                    optimizer.zero_grad(set_to_none=True)\n                    scheduler.step()\n                    if ema is not None:\n                        ema.update(unwrap(model))\n\n            non_pad = (trg_out != PAD).sum().item()\n            total_loss += (loss.item() * (hp.accum_steps if train else 1.0)) * non_pad\n            total_tok += non_pad\n\n    return total_loss / max(1, total_tok)\n\ndef save_ckpt(path, model, best_val, epoch, step):\n    state = {\n        \"model\": unwrap(model).state_dict(),\n        \"hparams\": hp.__dict__,\n        \"best_val\": float(best_val),\n        \"epoch\": int(epoch),\n        \"step\": int(step),\n        \"spm_vi\": SRC_MODEL_PREFIX + \".model\",\n        \"spm_en\": TRG_MODEL_PREFIX + \".model\",\n    }\n    torch.save(state, path)\n\ndef load_ckpt(path, model):\n    ckpt = torch.load(path, map_location=\"cpu\")\n    unwrap(model).load_state_dict(ckpt[\"model\"], strict=True)\n    return ckpt\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T05:22:40.499218Z","iopub.execute_input":"2025-12-17T05:22:40.499603Z","iopub.status.idle":"2025-12-17T05:22:40.509191Z","shell.execute_reply.started":"2025-12-17T05:22:40.499578Z","shell.execute_reply":"2025-12-17T05:22:40.508511Z"}},"outputs":[],"execution_count":14},{"id":"df7c969a","cell_type":"code","source":"best_val = 1e9\nbest_path = \"best_vlsp_transformer_spm.pt\"\nglobal_step = 0\n\nfor epoch in range(1, hp.epochs + 1):\n    tr_loss = run_epoch(model, train_loader, train=True)\n\n    if ema is not None:\n        ema.apply(unwrap(model))\n\n    va_loss = run_epoch(model, valid_loader, train=False)\n\n    if ema is not None:\n        ema.restore(unwrap(model))\n\n    lr = optimizer.param_groups[0][\"lr\"]\n    global_step += steps_per_epoch\n\n    print(f\"Epoch {epoch}/{hp.epochs} | train_loss {tr_loss:.4f} | val_loss {va_loss:.4f} | lr {lr:.2e}\")\n\n    if va_loss < best_val:\n        best_val = va_loss\n        save_ckpt(best_path, model, best_val, epoch, global_step)\n        print(\"  ✔ Saved best:\", best_path)\n\nprint(\"Best val loss:\", best_val)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T05:22:40.509901Z","iopub.execute_input":"2025-12-17T05:22:40.510242Z","iopub.status.idle":"2025-12-17T09:50:14.780301Z","shell.execute_reply.started":"2025-12-17T05:22:40.510204Z","shell.execute_reply":"2025-12-17T09:50:14.779264Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4849 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_55/2263669950.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/404 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 1/15 | train_loss 7.5251 | val_loss 6.1209 | lr 1.51e-04\n  ✔ Saved best: best_vlsp_transformer_spm.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4849 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/404 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 2/15 | train_loss 5.1713 | val_loss 4.2591 | lr 3.03e-04\n  ✔ Saved best: best_vlsp_transformer_spm.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4849 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/404 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 3/15 | train_loss 3.8832 | val_loss 3.4207 | lr 4.55e-04\n  ✔ Saved best: best_vlsp_transformer_spm.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4849 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7baf1e9865c0>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7baf1e9865c0>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/404 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 4/15 | train_loss 3.3302 | val_loss 3.0937 | lr 4.96e-04\n  ✔ Saved best: best_vlsp_transformer_spm.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4849 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/404 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 5/15 | train_loss 3.0459 | val_loss 2.9234 | lr 4.77e-04\n  ✔ Saved best: best_vlsp_transformer_spm.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4849 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/404 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 6/15 | train_loss 2.8688 | val_loss 2.8192 | lr 4.43e-04\n  ✔ Saved best: best_vlsp_transformer_spm.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4849 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/404 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 7/15 | train_loss 2.7363 | val_loss 2.7358 | lr 3.98e-04\n  ✔ Saved best: best_vlsp_transformer_spm.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4849 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/404 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 8/15 | train_loss 2.6261 | val_loss 2.6724 | lr 3.43e-04\n  ✔ Saved best: best_vlsp_transformer_spm.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4849 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/404 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 9/15 | train_loss 2.5296 | val_loss 2.6180 | lr 2.84e-04\n  ✔ Saved best: best_vlsp_transformer_spm.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4849 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7baf1e9865c0>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7baf1e9865c0>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/404 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 10/15 | train_loss 2.4447 | val_loss 2.5771 | lr 2.24e-04\n  ✔ Saved best: best_vlsp_transformer_spm.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4849 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/404 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 11/15 | train_loss 2.3702 | val_loss 2.5433 | lr 1.68e-04\n  ✔ Saved best: best_vlsp_transformer_spm.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4849 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/404 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 12/15 | train_loss 2.3081 | val_loss 2.5154 | lr 1.19e-04\n  ✔ Saved best: best_vlsp_transformer_spm.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4849 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/404 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 13/15 | train_loss 2.2582 | val_loss 2.4970 | lr 8.17e-05\n  ✔ Saved best: best_vlsp_transformer_spm.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4849 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/404 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 14/15 | train_loss 2.2217 | val_loss 2.4856 | lr 5.81e-05\n  ✔ Saved best: best_vlsp_transformer_spm.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4849 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/404 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 15/15 | train_loss 2.1980 | val_loss 2.4775 | lr 5.00e-05\n  ✔ Saved best: best_vlsp_transformer_spm.pt\nBest val loss: 2.477543691571929\n","output_type":"stream"}],"execution_count":15},{"id":"7ec647c6","cell_type":"markdown","source":"## 6) Beam search decode","metadata":{}},{"id":"19bffc3d","cell_type":"code","source":"@torch.no_grad()\ndef _no_repeat_ngram_ok(seq, next_tok, n):\n    if n <= 0 or len(seq) < n - 1:\n        return True\n    prefix = seq[-(n-1):]\n    new_ng = tuple(prefix + [next_tok])\n    seen = set()\n    for i in range(len(seq) - n + 1):\n        seen.add(tuple(seq[i:i+n]))\n    return new_ng not in seen\n\n@torch.no_grad()\ndef beam_search_decode(model, src_text: str, beam_size=6, max_len=MAX_LEN, length_penalty=0.7, no_repeat_ngram=3):\n    model.eval()\n    src_ids = [BOS] + sp_src.encode(src_text, out_type=int)[:max_len-2] + [EOS]\n    src = torch.tensor(src_ids, dtype=torch.long, device=device).unsqueeze(0)\n    enc, src_mask = unwrap(model).encode(src)\n\n    beams = [(0.0, [BOS])]\n    completed = []\n\n    for _ in range(max_len):\n        new_beams = []\n        for logp, seq in beams:\n            if seq[-1] == EOS:\n                completed.append((logp, seq))\n                continue\n\n            trg = torch.tensor(seq, dtype=torch.long, device=device).unsqueeze(0)\n            logits = unwrap(model).decode(trg, enc, src_mask)\n            lp = torch.log_softmax(logits[0, -1], dim=-1)\n\n            topk = torch.topk(lp, k=beam_size*3)\n            for score, tok in zip(topk.values.tolist(), topk.indices.tolist()):\n                if no_repeat_ngram and not _no_repeat_ngram_ok(seq, tok, no_repeat_ngram):\n                    continue\n                new_beams.append((logp + score, seq + [tok]))\n\n        if not new_beams:\n            break\n\n        def norm(item):\n            lp, s = item\n            L = max(1, len(s))\n            return lp / (L ** length_penalty)\n\n        new_beams.sort(key=norm, reverse=True)\n        beams = new_beams[:beam_size]\n\n    if not completed:\n        completed = beams\n\n    best = max(completed, key=lambda x: x[0] / (max(1, len(x[1])) ** length_penalty))[1]\n    out_ids = [i for i in best if i not in (BOS, EOS, PAD)]\n    return sp_trg.decode(out_ids)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T09:50:14.781783Z","iopub.execute_input":"2025-12-17T09:50:14.782067Z","iopub.status.idle":"2025-12-17T09:50:14.794788Z","shell.execute_reply.started":"2025-12-17T09:50:14.782034Z","shell.execute_reply":"2025-12-17T09:50:14.793837Z"}},"outputs":[],"execution_count":16},{"id":"eba9e02a","cell_type":"markdown","source":"## 7) Metrics (BLEU / TER / METEOR)","metadata":{}},{"id":"2d4ad2ba","cell_type":"code","source":"from sacrebleu.metrics import TER\nter_metric = TER()\n\nassert os.path.exists(PUB_VI), \"Không tìm thấy public_test.vi\"\nassert os.path.exists(PUB_EN), \"Không tìm thấy public_test.en -> không thể tính BLEU trên test\"\n\nwith open(PUB_VI, encoding=\"utf-8\") as f:\n    test_vi = [normalize_vi(l.strip()) for l in f if l.strip()]\n\nwith open(PUB_EN, encoding=\"utf-8\") as f:\n    test_en = [normalize_en(l.strip()) for l in f if l.strip()]\n\nn0 = min(len(test_vi), len(test_en))\ntest_vi = test_vi[:n0]\ntest_en = test_en[:n0]\nprint(\"Loaded TEST pairs:\", n0)\n\n@torch.no_grad()\ndef evaluate_test_subset(model, src_list, ref_list, beam_size=6, limit=500):\n    n = min(limit, len(src_list), len(ref_list))\n    preds = []\n    refs = ref_list[:n]\n\n    for i in tqdm(range(n), desc=f\"Decoding TEST({n})\", leave=False):\n        preds.append(beam_search_decode(model, src_list[i], beam_size=beam_size, max_len=MAX_LEN))\n\n    bleu = sacrebleu.corpus_bleu(preds, [refs]).score\n    ter  = ter_metric.corpus_score(preds, [refs]).score\n    meteors = [meteor_score([refs[i].split()], preds[i].split()) for i in range(n)]\n    meteor_avg = float(np.mean(meteors))\n\n    return {\"BLEU\": float(bleu), \"TER\": float(ter), \"METEOR\": float(meteor_avg), \"n\": int(n)}, preds\n\nload_ckpt(best_path, model)\nmodel.to(device).eval()\n\nTEST_LIMIT = 500\nmetrics_test, test_preds = evaluate_test_subset(\n    model, test_vi, test_en, beam_size=6, limit=TEST_LIMIT\n)\n\nmetrics_test\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T09:56:41.898105Z","iopub.execute_input":"2025-12-17T09:56:41.898723Z","iopub.status.idle":"2025-12-17T10:21:09.801778Z","shell.execute_reply.started":"2025-12-17T09:56:41.898695Z","shell.execute_reply":"2025-12-17T10:21:09.801058Z"}},"outputs":[{"name":"stdout","text":"Loaded TEST pairs: 3000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Decoding TEST(500):   0%|          | 0/500 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"{'BLEU': 42.815546103242156,\n 'TER': 49.45105215004574,\n 'METEOR': 0.6359299289390538,\n 'n': 500}"},"metadata":{}}],"execution_count":19},{"id":"9fa9e8be","cell_type":"markdown","source":"## 8) Error analysis","metadata":{}},{"id":"3bb6e5f3","cell_type":"code","source":"def extract_caps_phrases(s: str):\n    return re.findall(r\"(?:\\b[A-Z][a-z]+\\b(?:\\s+\\b[A-Z][a-z]+\\b)+)\", s)\n\ndef extract_numbers(s: str):\n    return re.findall(r\"\\d+(?:[.,]\\d+)?\", s)\n\ndef punctuation_signature(s: str):\n    return ''.join(re.findall(r'[.,;:!?()\\[\\]\"\\'`-]', s))\n\ndef length_bucket(ratio: float):\n    if ratio < 0.6:\n        return \"too_short\"\n    if ratio > 1.6:\n        return \"too_long\"\n    return \"ok\"\n\ndef error_analysis(srcs, refs, preds, topk=15):\n    rows = []\n    for s, r, p in zip(srcs, refs, preds):\n        r_caps = set(extract_caps_phrases(r))\n        p_caps = set(extract_caps_phrases(p))\n        cap_miss = len(r_caps - p_caps)\n\n        r_nums = set(extract_numbers(r))\n        p_nums = set(extract_numbers(p))\n        num_miss = len(r_nums.symmetric_difference(p_nums))\n\n        punct_diff = (punctuation_signature(r) != punctuation_signature(p))\n\n        ratio = (len(p.split()) + 1e-6) / (len(r.split()) + 1e-6)\n        rows.append((cap_miss, num_miss, int(punct_diff), abs(ratio - 1.0), ratio, s, r, p))\n\n    rows.sort(key=lambda x: (x[0], x[1], x[2], x[3]), reverse=True)\n    return rows[:topk]\n\n# ---- ERROR ANALYSIS ON TEST (500) ----\nassert \"metrics_test\" in globals(), \"Chưa có metrics_test – hãy chạy cell evaluate TEST trước\"\nassert \"test_preds\" in globals(), \"Chưa có test_preds – hãy chạy cell evaluate TEST trước\"\nassert \"test_vi\" in globals() and \"test_en\" in globals(), \"Chưa có test_vi/test_en\"\n\nn = metrics_test[\"n\"]\nbad = error_analysis(test_vi[:n], test_en[:n], test_preds[:n], topk=15)\n\nfor i, (cap_miss, num_miss, punct_diff, dist, ratio, s, r, p) in enumerate(bad, 1):\n    print(\"=\" * 90)\n    print(f\"[{i}] cap_miss={cap_miss} | num_miss={num_miss} | punct_diff={bool(punct_diff)} | len_ratio={ratio:.2f} ({length_bucket(ratio)})\")\n    print(\"SRC:\", s)\n    print(\"REF:\", r)\n    print(\"PRD:\", p)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T10:23:55.457878Z","iopub.execute_input":"2025-12-17T10:23:55.458499Z","iopub.status.idle":"2025-12-17T10:23:55.480941Z","shell.execute_reply.started":"2025-12-17T10:23:55.458454Z","shell.execute_reply":"2025-12-17T10:23:55.480357Z"}},"outputs":[{"name":"stdout","text":"==========================================================================================\n[1] cap_miss=5 | num_miss=0 | punct_diff=True | len_ratio=0.50 (too_short)\nSRC: Đánh giá một số đặc điểm lâm sàng, kết quả điều trị theo các thang điểm GCS, MRC, NIHSS và mRS.\nREF: Assessment some clinical features, outcome based on Glasgow Coma Scale (GCS), Medical Research Council UK (MRC), National Institute of Health Stroke Scale (NIHSS) and modified Rankin Scale (mRS).\nPRD: Evaluate some clinical features, treatment results according to GCS, MRC, NIHSS and mRS scores.\n==========================================================================================\n[2] cap_miss=3 | num_miss=0 | punct_diff=True | len_ratio=0.97 (ok)\nSRC: Nghiên cứu sử dụng các yếu tố (chuẩn mực chủ quan, nhận thức kiểm soát hành vi) trong mô hình lý thuyết về hành vi có kế hoạch (TPB) cùng việc kết hợp một số yếu tố được chỉ ra từ các nghiên cứu liên quan trước đó để lường sự phù hợp của nó.\nREF: The study used the factors (Subjective Norm (SN), Perceived Behavioral Control) in the model Theory of Planned Behavior (TPB) and use some other factors, based on the previous studies on the same subjects.\nPRD: The study used the factors (StQ, Behavioral Control) in the model of planned behavior theory (TPB) and a combination of a number of factors indicated from previous studies to measure its appropriateness.\n==========================================================================================\n[3] cap_miss=3 | num_miss=0 | punct_diff=False | len_ratio=0.92 (ok)\nSRC: Các yếu tố ảnh hưởng đến ý định mua thực phẩm hữu cơ tại quận Long Biên, Hà Nội\nREF: Factors Affecting Consumer’s Intentions in Buying Organic Foods in Long Bien District, Hanoi\nPRD: Factors affecting intention to buy organic foods in Long Bien district, Hanoi\n==========================================================================================\n[4] cap_miss=2 | num_miss=1 | punct_diff=True | len_ratio=1.11 (ok)\nSRC: Nghiên cứu của chúng tôi là nghiên cứu hồi cứu cho nhóm 16 bệnh nhân dị dạng động tĩnh mạch da đầu, được chẩn đoán và điều trị tại khoa Phẫu thuật hàm mặt và tạo hình, Bệnh viện Việt Đức từ năm 2009 đến năm 2018.\nREF: We retrospectively assessed the outcome after treatment of scalp arteriovenous malformations by thePlastic and Maxillofacial Surgery Department at Viet Duc university hospital between January 2009 and December 2018.\nPRD: Our study was a retrospective study for 16 patients with scalp arteriovenous malformations, diagnosed and treated at the Department of Maxillofacial and Plastic Surgery, Viet Duc Hospital from 2009 to 2018.\n==========================================================================================\n[5] cap_miss=2 | num_miss=0 | punct_diff=True | len_ratio=0.87 (ok)\nSRC: Chỉ số răng nhiễm fluor trong cộng đồng theo chỉ số Dean ở trẻ 12 tuổi là 0,13 theo phân loại của Tổ chức Y tế Thế giới năm 2013 thuộc cộng đồng không bị nhiễm fluor răng.\nREF: The Dean's index of community fluor contaminated teeth in 12-year-old children was 0.13. This was a community without fluor contaminated teeth according to the 2013 classification of the World Health Organization.\nPRD: The index of dental fluorosis in the community according to the Dean index in 12-year-old children is 0.13 according to WHO classification in 2013 and non-fluoridated community.\n==========================================================================================\n[6] cap_miss=2 | num_miss=0 | punct_diff=True | len_ratio=1.00 (ok)\nSRC: Báo cáo chung tổng quan ngành Y tế Việt Nam năm 2014 chỉ ra rằng rối loạn tâm thần là một trong năm nhóm bệnh chiếm tỷ trọng lớn trong tổng gánh nặng bệnh tật do các bệnh không lây gây ra.\nREF: The General Report of Vietnam's Health Sector in 2014 indicates that mental disorders are one of the five groups of diseases that account for a large proportion of the total disease burden caused by non-communicable diseases.\nPRD: The overall report of Vietnam's Ministry of Health in 2014 indicated that mental disorder was one of five groups of diseases, accounting for a large proportion of the total burden of diseases caused by non-communicable diseases.\n==========================================================================================\n[7] cap_miss=2 | num_miss=0 | punct_diff=False | len_ratio=1.26 (ok)\nSRC: Động lực làm việc của cán bộ y tế và một số yếu tố ảnh hưởng tại Trung tâm cấp cứu 115 Thanh phố Hồ Chí Minh năm 2020\nREF: Factors affecting the working motivation of health workers at the Ho Chi Minh City 115 Emergency Center in 2020\nPRD: Working motivation of health workers and some influencing factors at the Center for Emergency Medicine of 115 Thanh Ho Chi Minh city in 2020\n==========================================================================================\n[8] cap_miss=2 | num_miss=0 | punct_diff=False | len_ratio=0.91 (ok)\nSRC: Khảo sát tỷ lệ rối loạn lipid máu và mối liên quan giữa rối loạn lipid máu với một số chỉ số lâm sàng, cận lâm sàng ở người cao tuổi tăng huyết áp điều trị tại Bệnh viện đa khoa 115 – Nghệ An.\nREF: To survey the prevalence of dyslipidemia and the relationship between dyslipidemia and some clinical and subclinical indexs among the elderly patients with hypertension who were treated at 115 General Hospital - Nghe An.\nPRD: To investigate the prevalence of dyslipidemia and the relationship between dyslipidemia and some clinical and subclinical indicators in elderly patients with hypertension treated at 115 - Nghe An General Hospital.\n==========================================================================================\n[9] cap_miss=2 | num_miss=0 | punct_diff=False | len_ratio=1.00 (ok)\nSRC: Điều trị phẫu thuật hẹp niệu đạo sau mổ lỗ tiểu thấp: Kinh nghiệm ở 49 bệnh nhân\nREF: Surgical Treatment of Urethral Stricture After Hypospadias Repair: Experience on 49 Patients\nPRD: Surgical treatment of urethral strictures after hypospadias repair: experiences in 49 patients\n==========================================================================================\n[10] cap_miss=1 | num_miss=48 | punct_diff=True | len_ratio=0.44 (too_short)\nSRC: Kết quả: Nồng độ Acid uric, Ure, Creatinin, AST, ALT ở nhóm TSG cao hơn có ý nghĩa so với nhóm chứng lần lượt là: 469,73 ± 124,99 μmol / L so với 267,96 ± 47,96 μmol / L (p < 0,05); 6,75 ± 3,34 mmol / L so với 2,65 ± 0,59 mmol / L (p < 0,05); 71,73 ± 17,98 μmol / L so với 54,04 ± 4,56 μmol / L (p < 0,05); 31,20 ± 22,28 U / L so với 21,09 ± 5,01 U / L (p < 0,05); 22,53 ± 19,18 U / L so với 14,29 ± 7,55 U / L (p < 0,05).\nREF: Results: Plasma Uric acid, Urea, Creatinine, AST, ALT levels were significantly higher in pre-eclampsia group than control group, sequence: 469, 73 ± 124, 99 μmol / L versus 267, 96 ± 47, 96 μmol / L (p<0, 05); 6, 75 ± 3, 34 mmol / L versus 2, 65 ± 0, 59 mmol / L (p<0, 05); 71, 73 ± 17, 98 μmol / L versus 54, 04 ± 4, 56 μmol / L (p<0, 05); 31, 20 ± 22, 28 U / L versus 21, 09 ± 5, 01 U / L (p<0, 05); 22, 53 ± 19, 18 U / L versus 14, 29 ± 7, 55 U/L (p<0, 05).\nPRD: Results: The serum uric acid, urea, creatinine, AST, ALT were significantly higher in pre-eclampsia group than in the control group: 469.73 ± 124.99 μmol / L versus 267.96 ± 47.96 μmol/L (p<0.05); 6.75 ± 3.34 mmol / L vs 2.65 ± 0.59 mmol / l (p <0.05); 71.73 ±\n==========================================================================================\n[11] cap_miss=1 | num_miss=4 | punct_diff=True | len_ratio=0.57 (too_short)\nSRC: Xác định tỷ lệ đái tháo đường và mối liên quan giữa một số yếu tố với nguy cơ đái tháo đường sau sinh 6 tuần ở người bệnh đái tháo đường thai kì.\nREF: To evaluate prevalence 6 weeks postpartum diabetes and relative with some factors in women with gestational diabetes Subject and method: A cross-sectional and follow up to 6 weeks postpartum on 93 pregnant women with GDM from 7/2018 to 7/2019 at National Hospital of Endocrinology.\nPRD: To determine the prevalence of diabetes and the relationship between some factors and the risk of diabetes mellitus at 6 weeks postpartum in GDM patients.\n==========================================================================================\n[12] cap_miss=1 | num_miss=2 | punct_diff=True | len_ratio=1.29 (ok)\nSRC: Đối tượng và phương pháp nghiên cứu: Nghiên cứu mô tả cắt ngang được thực hiện trên 122 người bệnh có đợt cấp bệnh phổi tắc nghẽn mạn tính được điều trị tại Trung tâm Hô hấp bệnh viện Bạch Mai năm 2018, trong đó có 114 nam và 8 nữ.\nREF: Method: A cross-sectional study was conducted on 122 patients with Chronic Obstructive Pulmonary Disease (COPD) after the exacerbations by the Respiratory center at Bach Mai Hospital in 2018.\nPRD: Subjects and methods: A cross-sectional descriptive study was conducted on 122 patients with exacerbations of chronic obstructive pulmonary disease treated at the Respiratory Center of Bach Mai Hospital in 2018, including 114 men and 8 women.\n==========================================================================================\n[13] cap_miss=1 | num_miss=2 | punct_diff=True | len_ratio=1.00 (ok)\nSRC: Phương pháp: Báo cáo ca lâm sàng viêm cơ tim sau tiêm vacxin Pfizer phòng Covid-19, điều trị tại khoa Nội tim mạch bệnh viện đa khoa Đức Giang, trong thời gian tháng 12 năm 2021. Kết quả: 2 bệnh nhân trẻ nam giới có độ tuổi 16 và 17, sau tiêm vacxin Pfizer phòng Covid-19, 2 ngày xuất hiện triệu chứng: Hồi hộp, đánh trống ngực, đau ngực trái, mệt mỏi.\nREF: Methods: Report on clinical cases of myocarditis patients after vaccination with Pfizer's COVID-19 vaccine, treated at Department of cardiology at Duc Giang general hospital, December 2021 Results: 02 young male patients aged 16 and 17, 02 days after vaccination with Pfizer's COVID-19 vaccine showed symptoms: palpitations, left chest pain and fatigue.\nPRD: Methods: Report a clinical case of myocarditis after vaccination with Pfizer-BioNTech COVID-19 vaccine, treated at the Department of Cardiology, Duc Giang General Hospital, during December 2021 Results: 2 young male patients aged 16 and 17 years, after vaccination against Covid-19, 2 days of symptom onset: palpitations, chest pain, nausea and vomiting.\n==========================================================================================\n[14] cap_miss=1 | num_miss=1 | punct_diff=True | len_ratio=0.83 (ok)\nSRC: Phương pháp: Nghiên cứu mô tả cắt ngang kết hợp giữa định lượng và định tính dựa trên cơ sở thu thập thông tin từ phần mềm quản lý, phỏng vấn sâu cán bộ y tế và thảo luận nhóm bệnh nhân THA được quản lý tại TTYT huyện Gò Công Tây từ tháng 4 đến tháng 10/2021.Kết quả: Số người mắc THA được khám và điều trị ngày càng tăng hàng năm, tỉ lệ người bệnh đi tái khám đúng lịch là 63,6%.\nREF: Methods: A cross-sectional descriptive study combining quantitative and qualitative based on information collection from management software, in-depth interviews with medical staff and group discussion of hypertensive patients managed at the Go Cong Tay district health center from April to October 2021.Results: The number of people with high blood pressure being examined and treated is increasing every year, the rate of patients coming back for follow-up examination on schedule is 63.6%.\nPRD: Methods: A cross-sectional descriptive study combining quantitative and qualitative based on the basis of collecting information from management software, in-depth interviews with medical staff and focus group discussions of hypertensive patients managed at Go Cong Tay District Health Center from April to October 2021. Results: The number of people with hypertension were examined and treated increasingly every year.\n==========================================================================================\n[15] cap_miss=1 | num_miss=1 | punct_diff=True | len_ratio=1.13 (ok)\nSRC: Phương pháp: Thiết kế nghiên mô tả cắt ngang được thực hiện trên 928 người trưởng thành có thẻ bảo hiểm y tế tại 2 huyện Phone Hong và Keo Oudom, tỉnh Viêng Chăn.\nREF: Methodology: A cross sectional study was used among 928 adult health insurance card's holders in Phone Hong and Keo Oudom districts, Vientiane province.\nPRD: Methods: A cross-sectional descriptive study was conducted on 928 adults with health insurance cards in 2 districts of Phone Hong and Keo Oudam, Ho Chieng province.\n","output_type":"stream"}],"execution_count":20},{"id":"c3962918-4957-4b1c-9eb2-c456870a2ce3","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}